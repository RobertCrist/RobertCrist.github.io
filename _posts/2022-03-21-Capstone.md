---
title:  "Capstone"
layout: post
---

My capstone is through the ENGINE program at the UW ECE which pairs students with projects from companies, labs and research groups. I was paired with UW CSE's [Octopus Research Group](http://arl.cs.washington.edu/ORG/) with the goal of creating a VR experience to create empathy towards octopi. To do this, our team worked with the Unity game engine and created C# scripts, shaders, and animations. A link to the repository can be found [here](https://github.com/TStrong85/OctopusVR). 


Due to the diverse requirements, our team split the project into a plethora of distict portions that were complete on their own. This project is still ongoing and the following sections go over the work I have completed:

## Reaching Into and Exploring Opening
 ---
 
The first major task I was assigned was to get the octopus arms to be able to reach inside and explore openings. Due to my initial lack of experience in both AI and Unity, I started out creating a simple AI model before moving onto the the working with the octopus model. The AI I ended up created is a model that searches for an door opening. The follow shows the an example of the model searching for a door opening.

![simple AI](/assets/SimpleAI.gif)

To explore its surroundings, the AI finds a random point within a certain walking range, moves the that point, and repeats indefintiely. However, I soon realized that having purely random exploring leads the AI to meander and have sparatic pathing. I order to combat that, the AI remembers the three previous walk points (which are displayed as the yellow spheres), and ensures that the next walk point (displayed as a red sphere), is not within their radius.

In order for the AI to be able to find the door opening, I placed "checkpoints" around the house that allow the AI to know where it currently is. Once the AI is withing range of a given region, it moves inside that region where it cannot leave until it finds the next checkpoint. The checkpoints are shown below.

![HouseRegions](/assets/HouseRegions.png)

After completing this AI model, I began working on the tentacles. There was existing scripts which attracted the tentacles to a specfic point which I used as the baseline driver of the tentacle movement; however, I modified and added more functionality so that they fit my needs. From there, I modified the existing framework I had worked out with my previous AI model onto a jar. The following shows the checkpoints I defined for a jar. 

![JarCollisionRegions](/assets/JarCollisionRegions.gif)

From there, I defined the behavior I wanted a tentacle is in a specific region and the results are as follows.

![CubeModelGizmo](/assets/CubeModelGizmo.gif)
![OctopusModel](/assets/OctopusModel.gif)

The following is live gameplay recording of this reaching behavior. Minimal user input is required to acheive this. The user can only control the general direction of the tentacle while all fine movements of the tips are controlled by the AI model.

![ReachingPoV](/assets/ReachingMin25.gif)

## General Scripts
 ---
 
With the reaching behavior AI now finalized, my work shifted towards creating a unified experience. To do this, serveral gameplay mechanics needed to be made. The first of which was an object spawner to simulate items being thrown overboard by the fisherman. In order for this script to be adapdable, developers can easily change the item pool, spawn rate, as well as starting height and spawn area.

![spawner](/assets/spawner.gif)

After that, creating barriers was another important step in order to contain the player within the map. Due to the nature of the game, physical barriers were not an option as our team wanted to preseve the sense of openness of the ocean. To preserve this aspect of the enviornment, the barriers act as invisible forcefields.

![Barriers](/assets/Barrier.gif)

## Tutorial
 ---
 
The final portion of this project which our team worked on was creating a tutorial of all the mechanics that we created. In order to do this, we had to create manager scripts in order to sequence events in a paticular order. In addion to that, the script must be reliant on triggers that determine whether or not the user completed an assigned tasked. These scripts were individually created for each of the tutorial scenes by myself, and my groupmate Mayank Kumar. The following is a playthrough of the tutorial. 

<iframe width="560" height="315" src="https://www.youtube.com/embed/0tO61FgWZ5c" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

## Poster
 ---
 
The following poster was presented at the ENGINE Capstone Poster night and provides more general information about the project, as well as details on the work of my other group members.
 
![FinalPoster](/assets/FinalPoster.png)

